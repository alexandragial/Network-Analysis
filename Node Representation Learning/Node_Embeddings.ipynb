{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries**"
      ],
      "metadata": {
        "id": "-LlARvnhHbBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install node2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUyPuI1sptXE",
        "outputId": "f5e0bf13-7533-4f1a-86cf-2eeb7fa24a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: node2vec in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.3.2)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.3.2)\n",
            "Requirement already satisfied: networkx<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from node2vec) (2.8.8)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.23.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.55.1 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.1.2->node2vec) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.1.2->node2vec) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from sklearn import metrics\n",
        "from node2vec import Node2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import  accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "MWs5goQZk6Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btYYN0UKDprW"
      },
      "outputs": [],
      "source": [
        "filename = 'file.gml'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions**"
      ],
      "metadata": {
        "id": "fj8s8FU8pmBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Purity\n",
        "def calc_purity(true_labels, pred_labels):\n",
        "  \"\"\"\n",
        "    Calculates purity.\n",
        "\n",
        "    Args:\n",
        "      true_labels (list of lists): List of true labels' lists.\n",
        "      pred_labels (list of lists): List of predicted labels' lists.\n",
        "\n",
        "    Returns:\n",
        "      Value of purity.\n",
        "  \"\"\"\n",
        "  true_list = [label for label, c in enumerate(true_labels) for _ in range(len(c))]\n",
        "  pred_list = [label for label, c in enumerate(pred_labels) for _ in range(len(c))]\n",
        "\n",
        "  confusion_matrix = metrics.confusion_matrix(true_list, pred_list)\n",
        "\n",
        "  return np.sum(np.amax(confusion_matrix, axis=0)) / np.sum(confusion_matrix)"
      ],
      "metadata": {
        "id": "6iT8g8d9RdYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modularity\n",
        "def calc_modularity(graph, list_of_clusters):\n",
        "  \"\"\"\n",
        "    Calculates modularity of the clustered graph.\n",
        "\n",
        "    Args:\n",
        "      graph : A (un)directed graph\n",
        "      list_of_clusters (list of lists): List of cluster' lists\n",
        "\n",
        "    Returns:\n",
        "      Value of modularity.\n",
        "  \"\"\"\n",
        "  return nx.algorithms.community.modularity(graph, list_of_clusters)"
      ],
      "metadata": {
        "id": "-SPWAKDpRqb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_partition(df):\n",
        "\n",
        "  \"\"\"\n",
        "    Get the partition of nodes after applying an algorithm.\n",
        "\n",
        "    Args:\n",
        "      df (pandas dataframe) : Dataframe with node embeddings\n",
        "\n",
        "    Returns:\n",
        "      partition (list of lists) : The partition of nodes based on the predicted label\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a list with three inner empty lists\n",
        "  partition = [[],[],[]]\n",
        "  # Filter nodes' label\n",
        "  for node in range(len(df)):\n",
        "    if df.iloc[node, -1] == 0:\n",
        "      partition[0].append(df.iloc[node, 0])\n",
        "    elif df.iloc[node, -1] == 1:\n",
        "      partition[1].append(df.iloc[node, 0])\n",
        "    elif df.iloc[node, -1] == 2:\n",
        "      partition[2].append(df.iloc[node, 0])\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  return partition"
      ],
      "metadata": {
        "id": "H-mrapC1Uf8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_list_of_classes(dict_labels):\n",
        "\n",
        "  \"\"\"\n",
        "    Creates a list of lists given a dictionary of labels,\n",
        "    where each inner list respresents a real class.\n",
        "\n",
        "    Args:\n",
        "      dict_labels (dictionary): A dictionary of labels which has the form\n",
        "          {key = node : value = label}. The labels' values are n, c and l.\n",
        "\n",
        "    Returns:\n",
        "      list_classes (list of lists): List of labels' list\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a list with two inner empty lists\n",
        "  list_classes = [[],[],[]]\n",
        "  # Filter nodes' label\n",
        "  for node in dict_labels.keys():\n",
        "    if dict_labels[node] == 'n':\n",
        "      # Class 'n'\n",
        "      list_classes[0].append(node)\n",
        "    elif dict_labels[node] == 'c':\n",
        "      # Class 'c'\n",
        "      list_classes[1].append(node)\n",
        "    elif dict_labels[node] == 'l':\n",
        "      # Class 'l'\n",
        "      list_classes[2].append(node)\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  return list_classes"
      ],
      "metadata": {
        "id": "E_PoDwdOvm0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_true_labels(graph):\n",
        "\n",
        "  \"\"\"\n",
        "    Get the true labels of a graph from the 'value' attribute.\n",
        "\n",
        "    Args:\n",
        "      graph (undirected Graph) : Graph from a .gml file\n",
        "\n",
        "    Returns:\n",
        "      true_labels (list of lists): List of labels' list\n",
        "      node_values (dictionary): A dictionary of labels which has the form\n",
        "          {key = node : value = label} based on the graph attributes\n",
        "  \"\"\"\n",
        "\n",
        "  # Get the 'value' attribute of each node\n",
        "  node_values = dict()\n",
        "  for node in graph.nodes():\n",
        "    node_values[node] = graph.nodes[node]['value']\n",
        "\n",
        "  # Keep the nodes of each class into a list of lists\n",
        "  true_labels = create_list_of_classes(node_values)\n",
        "\n",
        "  return node_values, true_labels"
      ],
      "metadata": {
        "id": "6qH_L10OroSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_tsne(embeddings, pred_labels, title, legend):\n",
        "\n",
        "  \"\"\"\n",
        "    Plot the results using TSNE (a tool to visualize high-dimensional data)\n",
        "\n",
        "    Args:\n",
        "      embeddings (pandas dataframe) : A dataframe with the embeddings\n",
        "      pred_labels (numpy array) : An array that stores the predicted labels\n",
        "      from each algorithm\n",
        "      title (string) : 'Classification' or 'Clustering'\n",
        "      legend (string) : 'Class' or 'Cluster'\n",
        "\n",
        "    Returns: -\n",
        "  \"\"\"\n",
        "  # Creation of my colormap\n",
        "  colors = ['#2c6ae6', '#e62c51', '#e6c92c']\n",
        "  my_cmap = mcolors.ListedColormap(colors)\n",
        "\n",
        "  # Plotting the results with TSNE visualisation\n",
        "  tsne = TSNE(n_components = 2, random_state = 1)\n",
        "  data = tsne.fit_transform(embeddings)\n",
        "\n",
        "  scatter = plt.scatter(data[:, 0], data[:, 1], c = pred_labels,\n",
        "              marker = 'o', s = 50, cmap = my_cmap, edgecolors='black')\n",
        "  plt.xlabel('Dimension 1')\n",
        "  plt.ylabel('Dimension 2')\n",
        "  plt.title(title + ' Results with t-SNE')\n",
        "\n",
        "  # Add legends\n",
        "  legend_labels =[legend + ' 0', legend + ' 1', legend + ' 2']\n",
        "  plt.legend(handles = scatter.legend_elements()[0], labels = legend_labels)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ndgu_gMM-aHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_edge_embeddings(df, list_of_edges, pos_edges):\n",
        "\n",
        "    \"\"\"\n",
        "    Get the edge embeddings and the label of each edge.\n",
        "\n",
        "    Args:\n",
        "      df (pandas dataframe) : Dataframe with node embeddings\n",
        "      list_of_edges (list) : List of edges for training or testing\n",
        "      pos_edges (list): Pair of nodes which are connected with an edge\n",
        "\n",
        "    Returns:\n",
        "      embs (numpy array) : Edge embeddings\n",
        "      labels (list) : The label of each edge (1: exists, 0: doesn't exist)\n",
        "  \"\"\"\n",
        "\n",
        "    embs = []\n",
        "    labels = []\n",
        "\n",
        "    for edge in list_of_edges:\n",
        "      # Get the first and the second node from the tuple\n",
        "      node1 = edge[0]\n",
        "      node2 = edge[1]\n",
        "\n",
        "      # Get the label based on the pair of nodes\n",
        "      if (node1, node2) in pos_edges:\n",
        "        # Edge exists\n",
        "        labels.append(1)\n",
        "      else:\n",
        "        # Edge doesn't exist\n",
        "        labels.append(0)\n",
        "\n",
        "      # Find the embedding of each node\n",
        "      emb1 = np.array(first_df.iloc[node1, 1:])\n",
        "      emb2 = np.array(first_df.iloc[node2, 1:])\n",
        "\n",
        "      # Element-wise multiplication to combine the node embeddings\n",
        "      edge_emb = np.multiply(emb1, emb2)\n",
        "      embs.append(edge_emb)\n",
        "\n",
        "    embs = np.array(embs)\n",
        "\n",
        "    return embs, labels"
      ],
      "metadata": {
        "id": "3WINiSjuBoHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the undirected graph from the .gml file\n",
        "G = nx.read_gml(filename, label='id')\n",
        "\n",
        "G_nodes = len(G.nodes())\n",
        "G_edges = G.size()\n",
        "print(\"* The original graph G:\")\n",
        "print(\"Nodes:\", G_nodes)\n",
        "print(\"Edges:\", G_edges)\n",
        "print()\n",
        "\n",
        "node_values, true_class = get_true_labels(G)"
      ],
      "metadata": {
        "id": "dhglLarYmEQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the largest connected component of the graph\n",
        "lcc = max(nx.strongly_connected_components(G.to_directed()), key=len)\n",
        "# Create a subgraph using the set of nodes from the largest component\n",
        "H = G.subgraph(lcc)\n",
        "\n",
        "H_nodes = len(H.nodes())\n",
        "H_edges = H.size()\n",
        "\n",
        "print(\"* The largest connected component of the directed graph G turned into a subgraph:\")\n",
        "print(\"Nodes:\", H_nodes)\n",
        "print(\"Edges:\", H_edges)\n",
        "print(\"We notice that it is the same with graph G.\")"
      ],
      "metadata": {
        "id": "9ERUo1NxL9jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two empty lists for the existing and\n",
        "# the non-existing edges respectively\n",
        "positive_edges = []\n",
        "negative_edges = []\n",
        "\n",
        "for node1 in H.nodes():\n",
        "  for node2 in H.nodes():\n",
        "    if node1 != node2:  # Exclude self-loops\n",
        "      if H.has_edge(node1, node2) and node1 < node2:\n",
        "        positive_edges.append((node1, node2))\n",
        "      else:\n",
        "        negative_edges.append((node1, node2))"
      ],
      "metadata": {
        "id": "s73G8Cpa0T2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce number of negative edges to avoid imbalanced data\n",
        "random.seed(100)\n",
        "random.shuffle(negative_edges)\n",
        "negative_edges = negative_edges[:441]\n",
        "\n",
        "all_edges = positive_edges + negative_edges\n",
        "\n",
        "train_edges, test_edges = train_test_split(all_edges, test_size=0.3, random_state = 1)"
      ],
      "metadata": {
        "id": "TPEP-lNAAcl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1st experiment**"
      ],
      "metadata": {
        "id": "t0Y2J7xv_XZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "dim = 64\n",
        "q = 2\n",
        "p = 1\n",
        "\n",
        "# Generate random walks\n",
        "node2vec = Node2Vec(H, dimensions = dim, walk_length = 30, num_walks = 200, q = q, p = p, seed = 1)\n",
        "\n",
        "# Train node2vec model\n",
        "first_model = node2vec.fit(window = 10, min_count = 1, batch_words = 4)\n",
        "\n",
        "# Save embeddings\n",
        "first_model.wv.save_word2vec_format('first_model.txt')"
      ],
      "metadata": {
        "id": "VSNzf8NR_fZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the saved .txt file as a dataframe\n",
        "first_df = pd.read_csv('first_model.txt', sep=' ', skiprows=1, header = None)\n",
        "first_df = first_df.sort_values(by=[0])\n",
        "first_df = first_df.reset_index(drop=True)\n",
        "\n",
        "display(first_df)"
      ],
      "metadata": {
        "id": "zQ-wDCx1K05Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the edge embeddings and the label of each edge\n",
        "train_embs, train_labels = get_edge_embeddings(first_df, train_edges, positive_edges)\n",
        "test_embs, test_labels = get_edge_embeddings(first_df, test_edges, positive_edges)"
      ],
      "metadata": {
        "id": "s5qrLLQLGDYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_lg = LogisticRegression(random_state = 1)\n",
        "# Train the model\n",
        "first_lg.fit(train_embs, train_labels)\n",
        "# Prediction\n",
        "first_pred = first_lg.predict(test_embs)"
      ],
      "metadata": {
        "id": "JRSThKibNz-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "print('Accuracy:', accuracy_score(test_labels, first_pred))\n",
        "print('Precision:', precision_score(test_labels, first_pred))\n",
        "print('Recall:', recall_score(test_labels, first_pred))"
      ],
      "metadata": {
        "id": "8dSK4QdiQLfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, first_pred))"
      ],
      "metadata": {
        "id": "Dwa8OmdFV_Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KMeans Clustering**"
      ],
      "metadata": {
        "id": "fQ-0ieHS9mB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the dictionary values in a list based on the order of nodes in the dataframe\n",
        "new_values = []\n",
        "for node in list(first_df[0]):\n",
        "  new_values.append(node_values[node])\n",
        "\n",
        "# Convert true values (n, c, l) into (0, 1, 2) respectively\n",
        "for item in range(len(new_values)):\n",
        "  if new_values[item] == 'n' :\n",
        "    new_values[item] = 0\n",
        "  elif new_values[item] == 'c':\n",
        "    new_values[item] = 1\n",
        "  elif new_values[item] == 'l':\n",
        "    new_values[item] = 2\n",
        "  else:\n",
        "    continue"
      ],
      "metadata": {
        "id": "4Pou0R9CT623"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_km = KMeans(n_clusters = 3, random_state = 1, n_init = \"auto\")\n",
        "labels = first_km.fit_predict(first_df.iloc[:, 1:])"
      ],
      "metadata": {
        "id": "NST3l1MnO3Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tsne(first_df.iloc[:, 1:], new_values, 'Ground-Truth', 'Class')"
      ],
      "metadata": {
        "id": "ocJFvDZn2brl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tsne(first_df.iloc[:, 1:], labels, 'Clustering', 'Cluster')"
      ],
      "metadata": {
        "id": "ENAn4HO6_KG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column to the dataframe with the predicted label of each edge\n",
        "first_df['Pred. Label'] = labels\n",
        "display(first_df)\n",
        "\n",
        "# Get the partition based on the cluster labels\n",
        "partition = get_partition(first_df)"
      ],
      "metadata": {
        "id": "XU9fgVjcR2-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "print('Modularity:', calc_modularity(H, partition))\n",
        "print('Purity:', calc_purity(true_class, partition))"
      ],
      "metadata": {
        "id": "2l8T3-v4_h-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2nd experiment**"
      ],
      "metadata": {
        "id": "puZlTlMQNsmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "dim = 64\n",
        "q = 0.5\n",
        "p = 1\n",
        "\n",
        "# Generate random walks\n",
        "node2vec = Node2Vec(H, dimensions = dim, walk_length = 30, num_walks = 200, q = q, p = p, seed = 1)\n",
        "\n",
        "# Train node2vec model\n",
        "sec_model = node2vec.fit(window = 10, min_count = 1, batch_words = 4)\n",
        "\n",
        "# Save embeddings\n",
        "sec_model.wv.save_word2vec_format('sec_model.txt')"
      ],
      "metadata": {
        "id": "C81YebgNNsmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the saved .txt file as a dataframe\n",
        "sec_df = pd.read_csv('sec_model.txt', sep=' ', skiprows=1, header = None)\n",
        "sec_df = sec_df.sort_values(by=[0])\n",
        "sec_df = sec_df.reset_index(drop=True)\n",
        "\n",
        "display(sec_df)"
      ],
      "metadata": {
        "id": "xemB4RslNsma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the edge embeddings and the label of each edge\n",
        "train_embs, train_labels = get_edge_embeddings(sec_df.iloc[:, 1:],\n",
        "                                              train_edges, positive_edges)\n",
        "test_embs, test_labels = get_edge_embeddings(sec_df.iloc[:, 1:],\n",
        "                                            test_edges, positive_edges)"
      ],
      "metadata": {
        "id": "uQDaY70tUmgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sec_lg = LogisticRegression(random_state = 1)\n",
        "# Train the model\n",
        "sec_lg.fit(train_embs, train_labels)\n",
        "# Prediction\n",
        "sec_pred = sec_lg.predict(test_embs)"
      ],
      "metadata": {
        "id": "QWKJydtmUmgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "print('Accuracy:', accuracy_score(test_labels, sec_pred))\n",
        "print('Precision:', precision_score(test_labels, sec_pred))\n",
        "print('Recall:', recall_score(test_labels, sec_pred))"
      ],
      "metadata": {
        "id": "e5l86QOYUmgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, sec_pred))"
      ],
      "metadata": {
        "id": "6lxUo5UeV8Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KMeans Clustering**"
      ],
      "metadata": {
        "id": "LgX9MTLm9f_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the dictionary values in a list based on the order of nodes in the dataframe\n",
        "new_values = []\n",
        "for node in list(sec_df[0]):\n",
        "  new_values.append(node_values[node])\n",
        "\n",
        "# Convert true values (n, c, l) into (0, 1, 2) reespectively\n",
        "for item in range(len(new_values)):\n",
        "  if new_values[item] == 'n' :\n",
        "    new_values[item] = 0\n",
        "  elif new_values[item] == 'c':\n",
        "    new_values[item] = 1\n",
        "  elif new_values[item] == 'l':\n",
        "    new_values[item] = 2\n",
        "  else:\n",
        "    continue"
      ],
      "metadata": {
        "id": "c20Wtz5LUT0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sec_km = KMeans(n_clusters = 3, random_state = 1, n_init = \"auto\")\n",
        "labels = sec_km.fit_predict(sec_df.iloc[:, 1:])"
      ],
      "metadata": {
        "id": "SS9B8tDj81JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tsne(sec_df.iloc[:, 1:], new_values, 'Ground-Truth', 'Class')"
      ],
      "metadata": {
        "id": "SuLLKles2YT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tsne(sec_df.iloc[:, 1:], labels, 'Clustering', 'Cluster')"
      ],
      "metadata": {
        "id": "nldX_LW8EeOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column to the dataframe with the predicted label of each node\n",
        "sec_df['Pred. Label'] = labels\n",
        "display(sec_df)\n",
        "\n",
        "partition = get_partition(sec_df)"
      ],
      "metadata": {
        "id": "Yw3PG90g81Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "print('Modularity:', calc_modularity(H, partition))\n",
        "print('Purity:', calc_purity(true_class, partition))"
      ],
      "metadata": {
        "id": "QL9JmaZp20Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3rd experiment**"
      ],
      "metadata": {
        "id": "dXzQ6FUEOSOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "dim = 64\n",
        "q = 1\n",
        "p = 1\n",
        "\n",
        "# Generate random walks\n",
        "node2vec = Node2Vec(H, dimensions = dim, walk_length = 30, num_walks = 200, q = q, p = p, seed = 1)\n",
        "\n",
        "# Train node2vec model\n",
        "third_model = node2vec.fit(window = 10, min_count = 1, batch_words = 4)\n",
        "\n",
        "# Save embeddings\n",
        "third_model.wv.save_word2vec_format('third_model.txt')"
      ],
      "metadata": {
        "id": "cR-x8exROSOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the saved .txt file as a dataframe\n",
        "third_df = pd.read_csv('third_model.txt', sep=' ', skiprows=1, header = None)\n",
        "third_df = third_df.sort_values(by=[0])\n",
        "third_df = third_df.reset_index(drop=True)\n",
        "\n",
        "display(third_df)"
      ],
      "metadata": {
        "id": "EiZ-OwAfOSOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the edge embeddings and the label of each node\n",
        "train_embs, train_labels = get_edge_embeddings(third_df.iloc[:, 1:],\n",
        "                                              train_edges, positive_edges)\n",
        "test_embs, test_labels = get_edge_embeddings(third_df.iloc[:, 1:],\n",
        "                                            test_edges, positive_edges)"
      ],
      "metadata": {
        "id": "qhFzXr1WU5Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_lg = LogisticRegression(random_state = 1)\n",
        "# Train the model\n",
        "third_lg.fit(train_embs, train_labels)\n",
        "# Prediction\n",
        "third_pred = third_lg.predict(test_embs)"
      ],
      "metadata": {
        "id": "0FWv3VnPU5Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "print('Accuracy:', accuracy_score(test_labels, third_pred))\n",
        "print('Precision:', precision_score(test_labels, third_pred))\n",
        "print('Recall:', recall_score(test_labels, third_pred))"
      ],
      "metadata": {
        "id": "45jbvrldU5Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, third_pred))"
      ],
      "metadata": {
        "id": "TNao7BivVmJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KMeans Clustering**"
      ],
      "metadata": {
        "id": "7z2vAMax9o0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the dictionary values in a list based on the order of nodes in the dataframe\n",
        "new_values = []\n",
        "for node in list(third_df[0]):\n",
        "  new_values.append(node_values[node])\n",
        "\n",
        "# Convert true values (n, c, l) into (0, 1, 2) reespectively\n",
        "for item in range(len(new_values)):\n",
        "  if new_values[item] == 'n' :\n",
        "    new_values[item] = 0\n",
        "  elif new_values[item] == 'c':\n",
        "    new_values[item] = 1\n",
        "  elif new_values[item] == 'l':\n",
        "    new_values[item] = 2\n",
        "  else:\n",
        "    continue"
      ],
      "metadata": {
        "id": "Zo9z9Y7eZ1d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_km = KMeans(n_clusters = 3, random_state = 1, n_init = \"auto\")\n",
        "labels = third_km.fit_predict(third_df.iloc[:, 1:])"
      ],
      "metadata": {
        "id": "_jazjH9N9KMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tsne(third_df.iloc[:, 1:], new_values, 'Ground-Truth', 'Class')"
      ],
      "metadata": {
        "id": "oNYldHXh2RE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tsne(third_df.iloc[:, 1:], labels, 'Clustering', 'Cluster')"
      ],
      "metadata": {
        "id": "p5SMb-5NEhdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column to the dataframe with the predicted label of each node\n",
        "third_df['Pred. Label'] = labels\n",
        "display(third_df)\n",
        "\n",
        "partition = get_partition(third_df)"
      ],
      "metadata": {
        "id": "2DS9rWCMo0Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "print('Modularity:', calc_modularity(H, partition))\n",
        "print('Purity:', calc_purity(true_class, partition))"
      ],
      "metadata": {
        "id": "Rn1rmAB19KMx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}